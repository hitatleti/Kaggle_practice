{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.　モデルチューニング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LightGBMのハイパーパラメータのチューニング\n",
    "- scikit-learnのモデル利用\n",
    "- ニューラルネットワークの利用\n",
    "- アンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "# 分布の確認\n",
    "import pandas_profiling as pdp\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "# 前処理\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "# モデリング\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# matplotlibで日本語表示したい場合はこれをinstallしてインポートする\n",
    "# !pip install japanize-matplotlib\n",
    "# import japanize_matplotlib\n",
    "# %matplotlib inline\n",
    "\n",
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "x_train, y_train, id_train = df_train[['Pclass', 'Fare']], df_train[[\n",
    "    'Survived']], df_train[['PassengerId']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1　LightGBMのハイパーパラメータのチューニング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.1　手動チューニング\n",
    "1. 初期値の設定\n",
    "2. 学習結果に応じた個別チューニング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.2　自動チューニング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optunaを用いた自動チューニングの例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from optuna) (6.0)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.9.3-py3-none-any.whl (210 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from optuna) (4.64.0)\n",
      "Collecting sqlalchemy>=1.3.0\n",
      "  Downloading SQLAlchemy-2.0.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Collecting cmaes>=0.9.1\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from optuna) (1.21.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.11.3)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.10.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (4.4.0)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp38-cp38-win_amd64.whl (192 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\statistics\\appdata\\roaming\\python\\python38\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "Installing collected packages: greenlet, sqlalchemy, Mako, importlib-resources, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.9.3 cmaes-0.9.1 colorlog-6.7.0 greenlet-2.0.2 importlib-resources-5.10.2 optuna-3.1.0 sqlalchemy-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\statistics\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 詮索しないハイパーパラメータ\n",
    "params_base = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\":\"auc\",\n",
    "    \"learning_rate\": \"0.02\",\n",
    "    \"n_estimators\": 100000,\n",
    "    \"bagging_fleq\": 1,\n",
    "    \"seed\": 123,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # 詮索するハイパーパラメータ\n",
    "    params_tuning = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 256),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 200),\n",
    "        \"min_sum_hessian_in_leaf\": trial.suggest_float(\"min_sum_hessian_in_leaf\", 1e-5, 1e-2, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-2, 1e2, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-2, 1e2, log=True),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "\n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x_train, y_train))\n",
    "    for nfold in np.arange(5):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = x_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = x_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "        model = lgb.LGBMClassifier(**params_tuning)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr, \n",
    "                  eval_set=[(x_tr, y_tr), (x_va, y_va)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0,)\n",
    "        y_va_pred = model.predict_proba(x_va)[:, 1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "\n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化処理（詮索の実行）\n",
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.6992\n",
      "acc(best)=0.6992404745464817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 252,\n",
       " 'min_data_in_leaf': 60,\n",
       " 'min_sum_hessian_in_leaf': 0.009739830877756862,\n",
       " 'feature_fraction': 0.8018999555097835,\n",
       " 'bagging_fraction': 0.5949431124260618,\n",
       " 'lambda_l1': 0.1812977929299853,\n",
       " 'lambda_l2': 0.011197876549499167}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 詮索結果の確認\n",
    "trial = study.best_trial\n",
    "print(\"acc(best)={:,.4f}\".format(trial.value))\n",
    "print(f\"acc(best)={trial.value}\")\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 252,\n",
       " 'min_data_in_leaf': 60,\n",
       " 'min_sum_hessian_in_leaf': 0.009739830877756862,\n",
       " 'feature_fraction': 0.8018999555097835,\n",
       " 'bagging_fraction': 0.5949431124260618,\n",
       " 'lambda_l1': 0.1812977929299853,\n",
       " 'lambda_l2': 0.011197876549499167,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'objective': 'binary',\n",
       " 'metric': 'auc',\n",
       " 'learning_rate': '0.02',\n",
       " 'n_estimators': 100000,\n",
       " 'bagging_fleq': 1,\n",
       " 'seed': 123}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ベストなハイパーパラメータの取得\n",
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2　LightGBM以外のモデル利用"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learnの各種モデル\n",
    "- ニューラルネットワーク"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1　scikit-learnの各種モデル"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的にはどのモデルでも同じ手順で処理できる.\n",
    "\n",
    "1. モデル定義: importした関数を指定してモデルを定義\n",
    "2. 学習: .fitで学習を実行する\n",
    "3. .predictで推論処理を実行する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearnの各種モデルでの学習の際の注意点\n",
    "- 欠損値を埋めないと学習できない\n",
    "- すべて数値データにしないと学習できない\n",
    "- 数値データを正規化あるいは標準化する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ロジスティック回帰"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡単のため説明変数は'Pclass', 'Age', 'Embarked'の３つとする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルの読み込み\n",
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "# データセットの作成\n",
    "x_train = df_train[['Pclass', 'Age', 'Embarked']]\n",
    "y_train = df_train[['Survived']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Age', 'Embarked'には欠損値があるので, 欠損値を保管する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値補間: 数値データ\n",
    "x_train['Age'] = x_train['Age'].fillna(x_train['Age'].mean())\n",
    "# 欠損値補間: カテゴリ変数\n",
    "x_train[\"Embarked\"] = x_train['Embarked'].fillna(x_train['Embarked'].mode()[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ変数である'Embarked'をohe-hot-encodingで数値データに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ変数の数値データへの変換（one-hot-encoding）\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(x_train[['Embarked']])\n",
    "df_embarked = pd.DataFrame(ohe.transform(x_train[['Embarked']]).toarray(), columns=[f\"Embarked_{col}\" for col in ohe.categories_[0]])\n",
    "x_train = pd.concat([x_train, df_embarked], axis=1)\n",
    "x_train = x_train.drop(columns=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値データの正規化\n",
    "mms = MinMaxScaler()\n",
    "mms.fit(df_train[['Pclass']])\n",
    "df_train['Pclass'] = mms.transform(df_train[['Pclass']])\n",
    "\n",
    "mms.fit(df_train[['Age']])\n",
    "df_train['Age'] = mms.transform(df_train[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 5) (179, 5) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# 学習データと検証データの分割（ホールドアウト検証）\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7262569832402235\n",
      "[0 1 0 1 0]\n",
      "[[0.85951356 0.14048644]\n",
      " [0.20358813 0.79641187]\n",
      " [0.85501264 0.14498736]\n",
      " [0.28727379 0.71272621]\n",
      " [0.61610234 0.38389766]]\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logis = LogisticRegression()\n",
    "\n",
    "# 学習\n",
    "model_logis.fit(x_tr, y_tr)\n",
    "\n",
    "# 予測\n",
    "y_va_pred = model_logis.predict(x_va)\n",
    "print(f\"accuracy: {accuracy_score(y_va, y_va_pred)}\")\n",
    "print(y_va_pred[:5])\n",
    "\n",
    "# 確率値の取得\n",
    "y_va_pred_prob = model_logis.predict_proba(x_va)\n",
    "print(y_va_pred_prob[:5, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM（サポートベクターマシン）\n",
    "今回はSVMの分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6368715083798883\n",
      "[0 0 0 0 0]\n",
      "[[0.66192458 0.33807542]\n",
      " [0.5599569  0.4400431 ]\n",
      " [0.66089667 0.33910333]\n",
      " [0.57490543 0.42509457]\n",
      " [0.58408982 0.41591018]]\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "from sklearn.svm import SVC\n",
    "model_svm = SVC(C=1.0, random_state=123, probability=True)\n",
    "\n",
    "# 学習\n",
    "model_svm.fit(x_tr, y_tr)\n",
    "\n",
    "# 予測\n",
    "y_va_pred = model_svm.predict(x_va)\n",
    "print(f\"accuracy: {accuracy_score(y_va, y_va_pred)}\")\n",
    "print(y_va_pred[:5])\n",
    "\n",
    "# 確率値の取得\n",
    "y_va_pred_prob = model_svm.predict_proba(x_va)\n",
    "print(y_va_pred_prob[:5, :])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2　ニューラルネットワーク"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークを用いて学習する際の注意点\n",
    "- 欠損値を埋めないと学習できない\n",
    "- すべて数値データにしないと学習できない\n",
    "- 数値データを正規化あるいは標準化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad0fc5d8869b6c56ca488a3b2d7b4e5f68591369db564ad1b04a4da769807e22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
